{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 01: Introduction to Distant Viewing Toolkit (DVT)\n",
    "\n",
    "In this notebook we illustrate the usage of the core DVT functionality. We will use\n",
    "a short video file taken from the film *All the President's Men*. You can generate \n",
    "the same output using your own video files with the template at the end of the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prebuilt Pipelines\n",
    "\n",
    "The Distant Viewing Toolkit includes several methods for extracting and\n",
    "visualizing metadata from moving images that require minimal setup. For\n",
    "example, we can provide a filename and output directory to the\n",
    "`VideoCsvPipeline` class to run a pre-defined sequence of algorithms over\n",
    "our dataset. Here is the code to run the pipeline over our sample video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dvt.pipeline.csv import VideoCsvPipeline\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "VideoCsvPipeline(finput=join(\"videos\", \"all-presidents-men-sample.mp4\"), dirout=\"dvt-output-csv\").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may see some warnings from the underlying Deep Learning algorithms, but these\n",
    "can usually be ignored. After finishing, you should be able to see that the\n",
    "pipeline has produced a number of CSV files within the \"dvt-output-csv\" directory.\n",
    "The general idea is that a first pass was made over the video file to detect shot\n",
    "breaks. Then, a second pass applied a number of computer algorithms to the middle \n",
    "frame in each shot. For exaple, it reports the detected objects, faces, and colors.\n",
    "This pipeline is great for users who want to read the dataset into another software\n",
    "program, such as R, Excel, or SPSS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another pipeline produces a similar set of data, but produces output that can be\n",
    "visualized in a web browser. The same syntax as above can be used by replacing the\n",
    "CSV pipline object with `VideoVizPipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dvt.pipeline.viz import VideoVizPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VideoVizPipeline(finput=join(\"videos\", \"all-presidents-men-sample.mp4\")).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When this script finishes running, you should see a new directory called \"dvt-output-data\".\n",
    "Inside are several JavaScript, CSS, and HTML files. Under the subdirectories, there are\n",
    "also still images extracted from the input as well as JSON files capturing similar \n",
    "data to the CSV files in the first pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to see the visualization in your own browser, you will need to start a\n",
    "local server in the \"dvt-output-data\" directory. If you have access to a terminal,\n",
    "you can run `python3 -m http.server` within the directory. Otherwise, you may also\n",
    "start a Jupyter notebook server from within the directory \"dvt-output-data\" directory\n",
    "and open the file \"index.html\". (For longer workshops, we push these to GitHub pages,\n",
    "which handles the server part for us, but required more time and setup)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Applying Annotators to a Video File\n",
    "\n",
    "The pre-built pipelines are a convenient starting place. It is also possible\n",
    "to make use of the internal mechanisms provided by DVT to create a custom \n",
    "set of annotations on your data. We will show an example of this here.\n",
    "\n",
    "To start, we need to create a `FrameInput` object that points to our video\n",
    "file. This object handles grabbing frames from the input dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dvt.core import FrameInput\n",
    "fi = FrameInput(input_path=join(\"videos\", \"all-presidents-men-sample.mp4\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we construct a data extraction object by providing out input object as an input.\n",
    "There are various options that are possible here, such as providing the location of\n",
    "an audio file, but for now we will just use our input video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dvt.core import DataExtraction\n",
    "dextraction = DataExtraction(fi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the input and extraction objects created, we can now pass a list of \n",
    "annotator objects and run them over the input. Here, we will use an \n",
    "annotator called `DiffAnnotator`. The algorithm will compute\n",
    "differences between succesive frames; by setting the quantiles input to 50,\n",
    "we indicate that we want to output the median differences between these\n",
    "frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dvt.annotate.diff import DiffAnnotator\n",
    "\n",
    "dextraction.run_annotators([\n",
    "    DiffAnnotator(quantiles=[50])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the annotator has been run, the results are stored inside of the data\n",
    "extraction object. To retrieve them, we use the `get_data` method. Note that\n",
    "the algorithm has produced our desired annotations (called \"diff\") as well\n",
    "as a special set of annotations called \"meta\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = dextraction.get_data()\n",
    "dt.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we input only a single video file, the metadata record contains only\n",
    "a single line. Printing it out, we see that it gives some basic information\n",
    "about the video file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['meta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference annotator gives information about each frame in the\n",
    "input, such as the average value (how bright the image is) as well\n",
    "as the median difference between each frame and the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['diff']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column \"q50\" gives the pixel difference between each frame and\n",
    "\"h50\" gives the histogram difference between colors in each image.\n",
    "Used together, we can try to predict when there is a shot break in\n",
    "the source video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Aggregator for Cut Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, one usage of the difference annotations is to detect the boundary\n",
    "between shots. The distance viewing toolkit includes an aggregator (and algorithm\n",
    "which processes other annotations, rather than working from the original image \n",
    "data) that performs this calculation called `CutAggregator`. To use it, we \n",
    "specify the cutoff score used for detected differences (here, a \"q50\" score of\n",
    "3 or greater) and the minimum length of a new shot. Then, the aggregator is\n",
    "passed to the data extraction object's `run_aggregator` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dvt.aggregate.cut import CutAggregator\n",
    "dextraction.run_aggregator(CutAggregator(cut_vals={'q50': 3}, min_len=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the annotations, the aggregated data is stored inside of the `dextraction`\n",
    "and we can retrieve it with the `get_data` method. Here, notice that we now have\n",
    "a new data type called \"cut\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = dextraction.get_data()\n",
    "dt.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing out this data shows the estimated shots, of which there are estimated\n",
    "to be 12:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['cut']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example of how to put this all together for an analysis, here we\n",
    "will use the  framerate from the metadata to compute the length of each\n",
    "shot in seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['cut']['length_sec'] = ((dt['cut']['frame_end'] - dt['cut']['frame_start']) / dt['meta']['fps'].values)\n",
    "dt['cut']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following notebooks we will apply the full Distant Viewing approach to address\n",
    "research questions with these kinds of extracted values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your own data\n",
    "\n",
    "If you would like to run the DVT toolkit in your data, one good way to start\n",
    "is to apply the `VideoVizPipeline`. To do this, it is easiest to copy your \n",
    "data into the video folder in the workshop folder. Then, input the file name\n",
    "below and run the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dvt.pipeline.viz import VideoVizPipeline\n",
    "from os.path import join\n",
    "\n",
    "input_path = \"\"\n",
    "VideoVizPipeline(finput=join(\"videos\", input_path)).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your input file is large, the code above could take a while to finish running.\n",
    "In the case of a file longer than a couple of minutes, consider starting with the\n",
    "following, where you can manually set a fixed frequency for how frequently (in frames)\n",
    "the DVT annotators are applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dvt.pipeline.viz import VideoVizPipeline\n",
    "from os.path import join\n",
    "\n",
    "input_path = \"\"\n",
    "VideoVizPipeline(finput=join(\"videos\", input_path), frequency=1000).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
